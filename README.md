The four steps in the data analysis process are asking questions, wrangling data, analyzing data, and drawing conclusions. Data wrangling is the step between asking questions and analyzing data. The gathering, assessment, and cleaning of data support the rest of the analysis process.

Data gathering includes collecting data from a variety of sources into a programming environment. The four most common methods to gather data are extraction from text files, SQL queries, APIs, and web scraping methods.

Data assessment includes writing TODO notes where you categorize and explain issues in your data. These issues can be quality or tidiness issues. Quality issues, otherwise known as dirty data, involve inaccuracies like missing data or incorrect values. Tidiness issues, called messy data, are structural and can slow down analysis.  

Data cleaning is the process of taking those TODO notes and implementing them in code. From the original dataset, the analyst first creates a copy and writes code to fix the issue. Afterward, the analyst codes a unit test underneath to assure there are no regressions.

The Jupyter Notebooks below contain the notes on the three step process:

- [Overview](https://nbviewer.jupyter.org/github/Shane-Lester100/How-To-Wrangle-Data-Gathering-Assessing-and-Cleaning-Data/blob/master/Introduction%20Data%20Wrangling.ipynb)
- [Gathering Data](https://github.com/Shane-Lester100/How-To-Wrangle-Data-Gathering-Assessing-and-Cleaning-Data/blob/master/Gathering%20Data.ipynb)
- [Assessing Data](https://github.com/Shane-Lester100/How-To-Wrangle-Data-Gathering-Assessing-and-Cleaning-Data/blob/master/Assessing%20Data.ipynb)
- [Cleaning Data](https://github.com/Shane-Lester100/How-To-Wrangle-Data-Gathering-Assessing-and-Cleaning-Data/blob/master/Step%203%20Cleaning.ipynb)

Source: All of the notes are sourced from the Udacity data analysis bootcamp
